{"searchDocs":[{"title":"Introducing the Agentic Community","type":0,"sectionRef":"#","url":"/docs/about","content":"","keywords":"","version":"Next"},{"title":"Vision‚Äã","type":1,"pageTitle":"Introducing the Agentic Community","url":"/docs/about#vision","content":" To create a community around AI agents, accessible to all, developed collaboratively, and deployed efficiently to solve complex challenges at scale.  ","version":"Next","tagName":"h2"},{"title":"Mission‚Äã","type":1,"pageTitle":"Introducing the Agentic Community","url":"/docs/about#mission","content":" The Agentic Community unites companies, developers, researchers, and practitioners in an open ecosystem to advance the state of agentic systems. We commit to:  Cultivate open source frameworks, standards, and best practices that enable interoperability across agentic systemsFoster inclusive collaboration between industry, academia, independent developers, and end-usersAccelerate innovation through shared research, benchmarks, and technical resourcesEnsure agentic technologies evolve in alignment with human values, safety, and ethical principlesDemocratize access to agent technologies, making them available to all regardless of organizational size or resourcesCreate educational pathways and professional development opportunities in the agent ecosystemAdvocate for responsible governance and technological approaches that maximize societal benefit  ","version":"Next","tagName":"h2"},{"title":"Values‚Äã","type":1,"pageTitle":"Introducing the Agentic Community","url":"/docs/about#values","content":" Openness: We believe in transparent development processes, open standards, and freely accessible knowledge that enables widespread participation.  Collaboration: We value diverse perspectives and collective problem-solving over siloed development, recognizing that the most robust solutions emerge from community effort.  Inclusivity: We actively work to ensure our community welcomes participants of all backgrounds, experience levels, and organizational affiliations.  Innovation: We embrace experimentation, creative approaches, and breakthrough thinking to advance the field of agentic systems.  Responsibility: We prioritize the ethical implications of our work, considering safety, security, privacy, and the societal impact of autonomous agents.  Interoperability: We champion solutions that work together across platforms, creating a connected ecosystem rather than isolated tools.  Human-Centered Design: We develop agent technologies that amplify human capabilities, align with human needs, and remain under meaningful human control.  Sustainability: We build for long-term impact, maintaining stewardship of projects and ensuring the viability of our community for years to come.  ","version":"Next","tagName":"h2"},{"title":"Working Groups:‚Äã","type":1,"pageTitle":"Introducing the Agentic Community","url":"/docs/about#working-groups","content":" Agent Development  Agent Interoperability  Agent Operations  Agent Security ","version":"Next","tagName":"h2"},{"title":"Development Working Group","type":0,"sectionRef":"#","url":"/docs/Working Groups/development","content":"","keywords":"","version":"Next"},{"title":"Working Group Information‚Äã","type":1,"pageTitle":"Development Working Group","url":"/docs/Working Groups/development#working-group-information","content":" Slack: #agentic-community-wg-development  üìÑ Meeting Notes  üìÖ Meeting Invite - Sign up for the Google Group ","version":"Next","tagName":"h2"},{"title":"Interoperability Working Group","type":0,"sectionRef":"#","url":"/docs/Working Groups/interoperability","content":"","keywords":"","version":"Next"},{"title":"Working Group Information‚Äã","type":1,"pageTitle":"Interoperability Working Group","url":"/docs/Working Groups/interoperability#working-group-information","content":" Slack: #agentic-community-wg-interoperability  üìÑ Meeting Notes  üìÖ Meeting Invite - Sign up for the Google Group ","version":"Next","tagName":"h2"},{"title":"Operations Working Group","type":0,"sectionRef":"#","url":"/docs/Working Groups/operations","content":"","keywords":"","version":"Next"},{"title":"Working Group Information‚Äã","type":1,"pageTitle":"Operations Working Group","url":"/docs/Working Groups/operations#working-group-information","content":" Slack: #agentic-community-wg-operations  üìÑ Meeting Notes  üìÖ Meeting Invite - Sign up for the Google Group  ","version":"Next","tagName":"h2"},{"title":"Projects‚Äã","type":1,"pageTitle":"Operations Working Group","url":"/docs/Working Groups/operations#projects","content":" ","version":"Next","tagName":"h2"},{"title":"MCP Gateway & Registry‚Äã","type":1,"pageTitle":"Operations Working Group","url":"/docs/Working Groups/operations#mcp-gateway--registry","content":" The MCP Gateway &amp; Registry is an enterprise-ready platform that centralizes access to AI development tools using the Model Context Protocol (MCP). Instead of managing hundreds of individual tool configurations across your development teams, provide secure, governed access to curated AI tools through a single platform.  ","version":"Next","tagName":"h3"},{"title":"Agentic Reference Architecture‚Äã","type":1,"pageTitle":"Operations Working Group","url":"/docs/Working Groups/operations#agentic-reference-architecture","content":" The Agentic Reference Architectureaims to highlight the components needed for an Agentic AI platform. The reference architecture does not suggest tools as much as guide what kind of tools should be evaluated. Others may build implementations based on this architecture.  ","version":"Next","tagName":"h3"},{"title":"Agentic Templates‚Äã","type":1,"pageTitle":"Operations Working Group","url":"/docs/Working Groups/operations#agentic-templates","content":" The Agentic Templatesoffer a way to build agents on CI/CD platforms in a way that facilitates local experimentation with production deployments.  ","version":"Next","tagName":"h3"},{"title":"Agentic Productionalization‚Äã","type":1,"pageTitle":"Operations Working Group","url":"/docs/Working Groups/operations#agentic-productionalization","content":" The Agentic Productionalization guide steps through taking a code sample and iteratively applying best practices and patterns to building agents using the Agentic Templatesand Agentic Reference Architecture ","version":"Next","tagName":"h3"},{"title":"Evolving System Architecture: Integrating Agents into Workflow Systems","type":0,"sectionRef":"#","url":"/docs/Artifacts/evolving-systems-architecture","content":"","keywords":"","version":"Next"},{"title":"0. Abstract‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#0-abstract","content":" The landscape of system design has undergone a fundamental transformation from rigid, deterministic workflows, to adaptive, intelligent architectures capable of emergent behavior. This evolution represents a paradigm shift from purely rules-based systems, through AI-enhanced workflows, to autonomous agent-based frameworks that address open-ended problems with flexibility and creativity.  Traditional rules-based workflows operate within the confines of explicitly programmed logic; they follow predetermined decision trees and conditional statements. While reliable and predictable, these systems inherently limit their creators' ability to anticipate and codify every possible scenario. The introduction of generative AI marks the first major disruption to this paradigm, enabling systems to process natural language inputs and generate contextually appropriate responses, though still within relatively constrained parameters.  The emergence of agent-based architectures represents the next evolutionary leap, fundamentally redefining what automated systems can accomplish. Unlike traditional workflows that follow linear, predefined paths, or early AI implementations that enhanced specific tasks, agents possess the capacity for autonomous decision-making, dynamic goal adaptation, and emergent problem-solving behaviors that their designers never explicitly programmed.  This document equips technical leaders and architects with insights into differentiated characteristics of an agent-based system and what additional infrastructure and operational components one needs to consider while building an agent-based system.  Key Takeaways:  Understanding of agentic systems' distinct characteristicsEssential infrastructure and operational requirements for successful agent implementationsCritical considerations for security, observability, and human oversight  Through this analysis, organizations can better position to make informed decisions about adopting agent-based architectures and managing the transition from traditional rules based and deterministic workflows to AI agentic systems.  ","version":"Next","tagName":"h2"},{"title":"1. Introduction‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#1-introduction","content":" AI-based workflows represent a significant advancement, integrating traditional deterministic workflows with the capabilities of Large Language Models (LLMs). These workflows demonstrate enhanced adaptability, enabling them to effectively manage intricate tasks with the ability to drive business optimization. They excel in well-defined, repetitive tasks characterized by minimal variation and the necessity of consistent outcomes.  In contrast, autonomous agent-based systems break free from the constraints of pure rules-based thinking, enabling emergent behavior through the interaction of multiple specialized agents. Each agent, powered by LLM capabilities and enhanced with contextual resources, contributes to a collective intelligence that dynamically decomposes and solves complex problems. This approach introduces a new paradigm whereby solutions emerge from collaborative interaction of autonomous agents, instead of by prescribed, rigid rules.  ","version":"Next","tagName":"h2"},{"title":"1.1 What Are Agents and How Do They Differ From LLMs?‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#11-what-are-agents-and-how-do-they-differ-from-llms","content":" An AI agent contains an LLM as its reasoning core, but extends it with:  Memory system for context retention - unlike stateless LLMs, agents track context and remember previous interactions/decisionsTool integration for external capabilities - agents interact with external systems (APIs, databases, software) to accomplish tasksPlanning and orchestration logic for complex tasks - agents make decisions and execute actions without requiring human input for every step  [Image: agentsvllms.png] Unlike LLMs, agents follow a process of:  Perception - gather information from the environment or tools.Process - use an LLM to reason about the situation.Act - select and use tools or actions to perform the objective.Learn - update and persist the state to benefit future processes.  Characteristics\tLLM\tAgentBehavior\tReactive\tProactive Conversation\tSingle Turn\tMulti-step planning and execution Capabilities\tText generation\tUses tools to perform actions Memory\tLimited by context window\tMaintains memory  The process loop creates increasingly effective behavior over time. Utilizing multiple, purpose built agents, enables creating autonomous systems that are able to accomplish broader goals.  ","version":"Next","tagName":"h3"},{"title":"1.2 System Design‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#12-system-design","content":" When building systems with multiple AI agents powered by LLMs, organizations face an important challenge: how to balance letting the AI agents work independently while ensuring they do what humans want them to do.  Imagine three players in this situation (Fig. 1):  The human users who want tasks done.The AI agents that can independently think and work.The rules and guidelines that keep everything running smoothly.  On one hand, organizations want AI agents to be independent enough to figure things out - giving them the freedom to solve problems their way. This is called &quot;autonomy&quot;: can the AI handle new situations without needing human help?  On the other hand, organizations need to make sure these AI agents stay on track and do what is intended of them. This is called &quot;alignment&quot;: ensure a helper acts in the manner intended.  There are two kinds of alignment to consider:  Basic rules that the system developers build in (&quot;don't share private information&quot;).Personal preferences that each user can set (&quot;always confirm before making big decisions&quot;).  Source: Thorsten H√§ndler, Balancing Autonomy and Alignment(p7)Fig. 1. Balancing autonomy and alignment to human intention and values  Organizations can use the below matrix to balance AI autonomy with human goals. This matrix puts autonomy levels on one axis (horizontal) and alignment levels on the other axis (vertical). The approach works well for Large Language Model (LLM) systems that use multiple AI agents. Each point in the matrix shows how much freedom and control to give the AI. H√§ndler (Oct 2023) explains this framework in detail in the paper &quot;Balancing Autonomy and Alignment&quot;. LLM enabled workflows will typically fall in the L1: Adaptive Autonomy level and Agents in the L2: Self-Organizing level.  Level of Autonomy &amp; Alignment\tL0: Static\tL1: Adaptive\tL2: Self-OrganizingL0: Integrated\tRule-Driven Automation\tPre-Configured Adaptation\tBounded Autonomy L1: User-Guided\tUser-Guided Automation\tUser-Guided Adaptation\tUser-Guided Autonomy L2: Real-time Responsive\tUser-Supervised\tUser-Collaborative Adaptation\tUser-Responsive Autonomy  A well-designed multi-agent AI system rests on four core architectural pillars:  Agent Composition establishes the foundation by defining specialized agent roles, managing their memory requirements, and structuring their hierarchical relationships. This framework must support dynamic scaling as the system grows or task complexity increases.Multi-Agent Collaboration structures how these agents work together. It implements standardized communication protocols and intelligent task distribution while providing robust mechanisms for conflict resolution and quality control. This ensures that multiple agents can work harmoniously toward common goals while maintaining output consistency.Context Interface manages how agents access and utilize external data sources, specialized tools, and additional AI models. It maintains contextual awareness across agent interactions while ensuring efficient resource distribution and access control.Goal Driven Task Management breaks down user goals into manageable subtasks, tracks dependencies, orchestrates execution, and synthesizes results into coherent responses. This component acts as the system's central nervous system, coordinating all activities toward achieving user objectives.    Source: Thorsten H√§ndler, Balancing Autonomy and Alignment(p6)Fig. 2. Characteristic of a multi-agent system. A=Agent Composition, M=Multi-Agent collaboration, C=Context interface, G=Goal driven task management, B=Balancing between Alignment and Autonomy** The system design must address critical operational considerations including performance optimization, error handling, security, and monitoring. These elements ensure the system remains reliable and maintainable while effectively handling complex, interconnected tasks. Success depends on careful balance between these components, creating a flexible system that can evolve with changing requirements while maintaining consistent performance.  ","version":"Next","tagName":"h3"},{"title":"2. Building Blocks of Agentic Systems‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#2-building-blocks-of-agentic-systems","content":" An agentic AI system is composed of one or more agents working together to accomplish a one time (make travel arrangements for my trip), asynchronous (update a code base from Java 11 to Java 17), perpetual (or otherwise) task (always monitor this network and take actions to maintain network health). In addition to the LLM that drives the agent loop, agents are composed of some common building blocks such as tool, memory, session management, identity, and observability. This section explores both the infrastructure and operational building blocks of agentic systems.    ","version":"Next","tagName":"h2"},{"title":"2.1 Infrastructure Components‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#21-infrastructure-components","content":" The diagram above highlights a multi-tenant, workflow based system with emergent, agentic capabilities. On the left side of the line down the middle are components that are more workflows based systems, on the right side are new components for agentic systems. In the middle are components that are common to both, but may have some capabilities that need to be added to them.  2.1.1 Agentic Services‚Äã  Agent Gateway - Acts as the primary entry point for all agent interactions. The agent gateway provides a registry for agents, tools and Model Context Protocol (MCP) servers with authentication and authorization. The centralization of managing all these agentic services enables a central point to enforce proper auditing (logging) of all tool and agent requests. It supports standard service requirements such as health monitoring, rate limiting, versioning, and circuit breaking for handling failures.  Agents - The core agentic services. Agents are containerized applications running in an event driven, asynchronous manner. They interact with the agent gateway to access other agents and services, as well as the LLM gateway to access LLMs for processing.  LLM Gateway - Manages all communication with LLMs. The LLM gateway enables intelligent request caching that can be shared amongst models and services. Similar to the agent gateway, centralizing LLM access enables enforcing security such as prompt injection protection and content filtering. Additionally, it can be used to track API keys for tasks and teams as well as pick appropriate models to route to based on the requirements and costs.  Memory - Dedicated storage systems for agent memory. The memory service handles short-term and long-term memory in either an ephemeral or persistent manner. It supports memory sharing with appropriate permissions, contextual memory retrieval, and memory prioritization for effective context use. Finally, it supports forgetting to allow outdated information to be dropped.  RAG (Retrieval Augmented Generation) - **** Knowledge storage and retrieval systems. The RAG service is a vector store for document embeddings which enables searching over additional organizational context to augment an LLM‚Äôs knowledge.  Agent Observability - Specialized monitoring for agent-specific metrics. Agent observability tooling enables augmenting traditional observability for storing agent based metrics, logs, and traces, as well as storing the same from the agent gateway and LLM gateway. It provides a way to track and associate token use with quality as a way to calculate value of the agent. By tracking task completion rates, errors, user feedback, and enabling prompt management, it enables teams to get a holistic view of how their agentic system is performing. Observability should be a cornerstone of enabling evaluation metrics for agent performance, LLM as a Judge (LLMaaJ), and RAG.  2.1.2 Common Services‚Äã  Service Registry - New services need to be added to traditional registries. A central registry and management console for AI agents, tools, and MCP servers needs to support governance, transparency, discoverability, and lifecycle management. It maintains a certified catalog of agents with essential metadata including identity, capabilities, ownership, and access permissions. The registry functions as the central hub for enforcing security policies, compliance checks, performance tracking, and agent lifecycle management.  Traditional Observability- Existing observability platforms need to be updated to support ingestion of the agent observability metrics, logs, and traces and correlating them with the existing services of the environment, as well as the observability logged from the agents‚Äô containers.  Data Lake- Traditional data sources need to be augmented to support secure access for agents. Data lineage needs to be available to understand both how the service (agent) and the user who used the service accessed the data and why. Understanding whether the right data was retrieved for the given request ensures that agents are presenting the correct data and that the agent is being valuable.  Queues- Agentic architectures require event-driven support. A messaging system needs to be available for agents as their communication may time out traditional HTTP communication. Enabling priority queues allows critical agent tasks to happen first, while supporting dead letter queues for errors is imperative. Finally, the ability to replay events is critical for time traveling and debugging agent interactions.  Identity Provider (IdP)- Identity needs to support agents, tools, and user roles and scopes. Agents act on behalf of users, allowing access to tools, data, and other agents. Enabling support for this fine-grained control is imperative to ensuring systems stay secure. Just-in-time privilege elevation enables HITL (human in the loop) to approve riskier agentic capabilities.  Load Balancing - Stochastic reasoning requires new load balancing techniques. As agents have non-deterministic processing times for similar inputs, load balancing needs to be aware of the current load of an agent rather than using traditional round-robin load balancing.  Service Mesh- Service mesh features such as circuit breaking traffic policies enable more robust agentic infrastructures. Agentic protocols such as MCP and A2A require layer 7 routing (more on communication below).  ","version":"Next","tagName":"h3"},{"title":"2.2 Communication Protocols‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#22-communication-protocols","content":" Several communication protocols between agents and tools and agents to agents exist:  MCP: Model Context Protocol is an open standard designed to streamline and standardize how AI applications-such as chatbots, IDE assistants, and custom agents-connect with external tools, data sources, and systems (and potentially agents, soon). MCP addresses the ‚ÄúMxN‚Äù integration problem by introducing a universal protocol that transforms the challenge into a simpler &quot;M+N&quot; scenario: tool creators build MCP servers for each system and application developers build MCP clients for each AI application; thereby allowing any compliant model to interact with any compliant tool without bespoke code.  A2A: Agent to agent is an open protocol developed by Google and partners to allow AI agents to securely communicate, exchange information, and coordinate actions. Designed to overcome the challenges of deploying large-scale, multi-agent systems, A2A provides a standardized foundation for agent discovery, task negotiation, and collaboration, while preserving agent opacity and security. It uses familiar technologies (JSON-RPC 2.0 over HTTP/S, Server-Sent Events) and introduces the Agent Card for capability discovery and Artifacts for structured results. The protocol is open-source and community-driven, aiming to foster a more interconnected AI ecosystem.  ACP: Agent Connect Protocol is developed as part of AGNTCY, an open-source, multi-company initiative, to create the foundational infrastructure for an ‚ÄúInternet of Agents.‚Äù It focuses on establishing open standards and protocols that allow diverse AI agents to discover, communicate, and collaborate across platforms and organizations. AGNTCY‚Äôs architecture is built on two main specifications: the Open Agent Schema Framework (OASF) for standardized agent metadata and the Agent Connect Protocol (ACP) for secure, robust agent communication. The initiative emphasizes security, scalability, and composability, enabling developers to build, deploy, and monitor complex multi-agent workflows with confidence.  A comparison of the three follows:  Feature\tModel Context Protocol (MCP)\tAgent2Agent (A2A) Protocol\tAGNTCYPrimary Focus\tAgent/Model to Tool/Data Integration\tAgent-to-Agent Communication/Collaboration\tFull Ecosystem Infrastructure Originator(s)\tAnthropic\tGoogle (+ Partners)\tOpen Collective (Cisco, LangChain, LlamaIndex, Galileo, and many others.) Scope\tFocused Protocol Standard\tFocused Protocol Standard\tComprehensive Suite of Protocols &amp; Services Core Interaction\tTools, Resources, Prompts\tTasks, Messages, Parts, Artifacts\tACP (Invocation, Interrupts) + AGP(Agent Gateway Protocol) Transport Architecture\tClient-Host-Server\tDirect Client-Server\tLayered (ACP/AGP/Gateway/Directory/OASF) Primary Transport\tStdio, HTTP+SSE\tHTTP(S) + SSE\tACP (REST-like) over AGP (gRPC/HTTP/2) Message Format\tJSON-RPC\tJSON-RPC\tACP (JSON, natural language) + AGP (Protobuf likely) Discovery\tHost connects to known Servers\tAgent Card @ well-known URL\tAgent Directory + OASF Manifests Key Security Locus\tHost Enforcement, User Consent\tStandard Web Security (HTTPS, Auth Schemes)\tInfrastructure (Gateway), Planned Frameworks Advanced Security\tStandard Web Auth (OAuth)\tStandard Web Auth (OAuth)\tStated AGP goals: E2E Encrypt, MLS, Quantum Safe  Successfully integrating agentic AI into traditional workflows requires both specialized new services and enhancements to existing infrastructure. Enhancing traditional services to support emergent behaviors requires a focus on security, asynchronous architectures, discoverability, and observability.  ","version":"Next","tagName":"h3"},{"title":"3. Unique Considerations for Agentic Systems‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#3-unique-considerations-for-agentic-systems","content":" Successful implementation of agentic systems requires careful considerations due to the unique nature of these systems. This section goes into some of the technical and operational challenges of implementing agentic systems as well as how to mitigate some of the potential challenges.  ","version":"Next","tagName":"h2"},{"title":"3.1 Technical Challenges‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#31-technical-challenges","content":" 3.1.1 Non-deterministic Behavior - Balancing Agent Independence With System Control‚Äã  Foundation models (FM) are inherently stochastic: there is a fundamental randomness in their output even when using the same input and same set of inference parameters across multiple runs. This poses a challenge as organizations build more and more complex generative AI systems using FMs because of the desire for these systems to produce reliable/deterministic outputs while being driven by stochastic models. Evaluations become an important step towards addressing the inherent non-deterministic behavior. There are several open-source agent benchmark datasets (Taubench, SWE-bench, others) and evaluation frameworks (Agent Eval, Holistic Agent Leaderboard (HAL)) that help with agent evaluations. Regarding reliability metrics:  Capability a.k.a Pass@k: if the agent is able to successfully complete a task in at least 1 out of k attempts.Reliability a.k.a Pass^k: if the agent is able successfully complete a task in all k out of k attempts.  The higher the capability score, the more likely an agent is to accomplish a task successfully. Ensuring that agents are continuously evaluated before and after deployment is imperative to successful agentic systems.  3.1.2 Cross-Boundary Tracing‚Äã  All agent frameworks provide traces that contain a representation of the tool to call at any given step and the parameters to pass that tool. These traces can be compared against a ground truth or evaluated by an LLMaaJ to determine the accuracy of the tool selection and usage. This metric is a derived metric; it would need to be determined by an agent evaluation framework. As agents work with LLMs and other external systems, there may be gaps in traces that are sent externally. Observability solutions which can visualize this information and export it to other solutions are important for ensuring agentic systems are running properly. They help track latency and expose regressions. They help identify models that perform faster, while giving outputs that are still accurate. Most of the observability solutions are integrated into the agent by instrumenting the code. Solutions such as LangSmith, Langfuse, Helicone, Weave, Phoenix, Opik, OpenLLMetry, and several others can be used for agent observability.  3.1.3 Self-Assembling Workflows‚Äã  Self-assembling workflows refer to the ability of agents to find other agents at runtime through an agent registry if they are assigned a task that they cannot accomplish given the tools they have. Agents can then communicate with other agents through an inter-agent protocol to collaboratively complete tasks. The ability to self-assemble workflows is critical to building reusable, autonomous, emergent systems. Supporting this functionality requires control plane infrastructure such as an agent gateway and registry that provide a protocol for these agents to communicate and handle governance aspects such as passing authentication credentials and ensuring no access control rules are breached.  ","version":"Next","tagName":"h3"},{"title":"3.2 Operational Considerations‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#32-operational-considerations","content":" 3.2.1 Security Considerations‚Äã  Agentic AI security concerns require organizations to implement robust risk management strategies, including multi-layered security frameworks and careful limitations on AI autonomy in high-risk scenarios. The balance between leveraging AI capabilities and maintaining security remains a critical challenge along a multitude of dimensions:  Data Integrity and System Exploitation: agents can be vulnerable to malicious actors and made to perform harmful tasks. The addition of agentic entrypoints creates a larger attack surface.Privacy and Data Protection: agents are given access to data and may retrieve unauthorized data.Autonomy-Related Risks: agent autonomy may lead to undetermined data access.Systemic and Operational Risks: agents interacting with traditional services add another vector for more sophisticated attacks or disruptions.Transparency and Trust Issues: agent autonomy makes it hard to keep track of the decision-making process, especially with lack of visibility across systems. When an incident happens, who is to blame?Compliance and Governance Challenges: regulatory requirements are rapidly evolving to incorporate autonomous systems.Tool Poisoning: external services introduced in agentic systems may have security vulnerabilities or intentionally placed malicious code to attack systems.  These are just some of the risks in an agentic architecture. Security should be addressed at multiple levels to protect across multiple threat levels  A combination of the following approaches helps address the challenges listed above.  Network security: deploy the agent in a secure virtual private cloud (VPC) so that it is solely accessible from allow listed endpoints. If the agent services external customers, access to the agent should be controlled via an API Gateway connected to an OAuth 2.1 compliant identity provider issuing access token to an application.IAM Based Access Control for Service to Service Authentication: the agent is accessible to services that use an IAM role that has authorization to access the agent.Data Security: all data sent to or received from the agent is encrypted in transit and at rest. When a tool accesses another system via an API then that message exchange is also encrypted via TLS.Observability: metrics, logs, and traces are critical to ensuring secure systems. Access to them should be secured and privacy protecting.Responsible AI (RAI): associate agents with Responsible AI Guardrails providing functionality such as: topic adherence, content filtering, sensitive information redaction, and preventing jailbreaks. Associate RAI Guardrails (such as NVIDIA NeMo guardrails) with an agent so that they are implicitly triggered upon agent invocation (for example from a chatbot based on user input).Curated Tool/MCP/Agent Registries: similar to traditional supply-chain security, solely allow known servers and services to be used.Task Based Access: Authorization/authentication should be evaluated per task. Access should be finely scoped and short lived.Dynamically Adjustable Security: Security should adjustable to give differing levels of control based on task risk as well as system threat levels.  3.2.2 Cost Management (Compute + LLM Usage)‚Äã  Cost and latency metrics are especially important in the context of agent evaluations as compared to model evaluations because a single agent invocation usually results in several calls to potentially multiple LLMs. An agent may also successfully accomplish a task by following a non-optimal trajectory or having a self-reflection pattern which allows it to correct errors, thus taking more steps than required in the most optimal scenario. Having additional steps in completing a task results in additional cost and latency. The latency metric is emitted by all agent frameworks as part of the agent invocation response. The cost metric is a derived metric. The HAL (Holistic Agent Leaderboard) provides:  Cost-controlled and reproducible evaluations, with detailed logging, cost tracking, and automated failure analysis.A public leaderboard that allows for transparent comparison of agent performance on accuracy and cost, with in-depth failure analysis and encrypted trace sharing to protect benchmark integrity.  This allows organizations to identify candidate models for testing in their agentic systems that may address their needs.  3.2.3 Performance Metrics‚Äã  Along with cost, understanding performance is the way to identify if the agentic system is providing value. Doing so requires an evaluation of a few metrics:  Token Counts: Prompt and generation token counts are the core metrics tracked for every step of an agent invocation. These metrics are emitted by all agent frameworks as part of the agent invocation response.  Task Completion Accuracy: Assesses whether an agent successfully achieved its assigned goal. The specific evaluation method varies based on the benchmark dataset being used. For example, in the USACO coding benchmark, accuracy is measured by the agent's code passing predefined unit tests with specific input-output pairs. This is a derived metric.  Tool Selection Quality (TSQ): TSQ is a compound metric that refers to how accurately an LLM selected the correct tool and how often it passed the correct parameters (values, data types) to the tool. All agent frameworks provide traces that contain a representation of the tool to call at any given step and the parameters to pass to that tool. These traces can be compared against a ground truth or evaluated by a LLMaaJ to determine the accuracy of the tool selection and usage. This is a derived metric.  Trajectory Evaluation Score: Trajectory refers to the sequence of steps followed by an agent to accomplish a task. This sequence can be compared with an available ground truth and reasoned upon by an LLM evaluator as part of trajectory evaluation. Trajectory evaluators provide a trajectory evaluation score per task which can then be averaged over a benchmark dataset to determine how efficient an agent is in accomplishing tasks in a given benchmark. This is a derived metric.  Responsible AI Guardrail Violations: Guardrails are associated with an AI agent and guardrail violations (such as hitting denied topics, including PII information, or failing content moderation) are important metrics to track for an agent. This metric is a derived metric.  Understanding these metrics along with the cost component of a LLM will allow organizations to gauge the effectiveness of their agents. Selecting a different LLM, changing the prompt, or different memory strategies may be required to increase an agent‚Äôs performance.  3.2.4 Human in the Loop Mechanisms (HITL)‚Äã  HITL interventions are used for agents when they require human validation while executing a tool, escalating privileges for data access, validating user input before acting on it, making a correction on a previous response, or when seeking additional context.    Agent frameworks typically implement HITL in one of two ways: with an explicit instruction provided by the Agent SDK or as a step implemented as a tool. The riskier an action is, the more likely HITL needs to be invoked. Tracing agent actions leading to HITL intervention, the output of the intervention, and the outcome of the agent enables organizations to understand whether there is continued need for this mechanism.  3.2.5 Agent Orchestration‚Äã  Agent orchestration refers to the coordination, management, and workflow control of one or more AI agents to accomplish complex tasks. Three commonly used approaches for agent orchestration are:  Supervisor Agent Driven Orchestration: in a multi-agent system, a supervisor agent controls the workflow. It usually has some form of routing logic (either as part of its system prompt or an external intent classifier) to delegate tasks to collaborator agents.Decentralized Orchestration: a network of agents can communicate with each other based on predefined protocols without central controls. For example, a multi-agent system where agents negotiate and self-organize to complete tasks.Event-Driven Orchestration: Agent execution is triggered based on events, messages, or state changes. For example, an agent that gets triggered based on anomaly detected by a system that is published as an event on an event bus.    Choosing an appropriate orchestration strategy requires understanding the complexity of the task, the predictability of the workflow, the complexity of the implementation, along with the scalability needs.  ","version":"Next","tagName":"h3"},{"title":"4. Open System Design Questions‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#4-open-system-design-questions","content":" What protocols and interfaces should standardize agent discovery, authentication, and communication across platforms and organizations?Is one registry for agents, tools, and MCP servers with shared metadata standards the right solution, or separate specialized registries for each component type?How to implement secure, scalable access management when agents need to operate across organizational boundaries while maintaining proper authorization and audit trails?Should agents maintain distributed state stores, rely on centralized memory systems, or use hybrid approaches - and how to ensure consistency during multi-agent collaboration?What are the essential patterns for human oversight, approval workflows, and fail-safes that prevent autonomous agents from causing unintended consequences?How to design cost controls, rate limiting, and resource allocation systems that work fairly across shared agent infrastructure?Should agents be designed as model-agnostic with universal interfaces, or optimized for specific LLMs - and what abstraction layers enable maximum compatibility?  ","version":"Next","tagName":"h2"},{"title":"5. Conclusion and Next Steps‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#5-conclusion-and-next-steps","content":" The transition from traditional rule based workflows to agent-based systems demands a carefully orchestrated approach that balances innovation with operational stability. Organizations can leverage existing infrastructure while building new capabilities through a structured evolution of their technical and operational framework.  Successful implementation begins with architectural flexibility. While current infrastructure components such as containerization, API management, and monitoring systems provide a solid foundation, organizations must extend these to support multiple protocol standards and emerging agent communication frameworks. This flexible architecture should accommodate both traditional workflow patterns and new agent interaction models, allowing for gradual transformation without disrupting existing operations.  The governance framework represents a critical bridge between existing and new paradigms. Traditional role-based access control and audit mechanisms must evolve to support more nuanced agent autonomy management. Organizations need to implement sophisticated control systems that can dynamically adjust agent freedom based on context, risk level, and operational requirements. This includes developing new monitoring approaches that can track both deterministic workflows and emergent agent behaviors.  Evaluation infrastructure requires significant enhancement to address the unique characteristics of agent-based systems. While existing testing frameworks and performance monitoring tools provide a starting point, organizations must develop new capabilities for assessing agent collaboration, measuring autonomous decision quality, and validating emergent behaviors. This involves combining automated testing with human oversight in novel ways, particularly for critical operations where agent actions must align precisely with organizational objectives.  The human and organizational aspects of this transition cannot be overlooked. Success requires developing new roles and capabilities specifically focused on agent operations, while maintaining expertise in traditional systems. Organizations should foster a culture that balances experimentation with operational discipline, creating space for innovation while ensuring reliability. This often means establishing dedicated teams that can bridge the gap between traditional IT operations and agent-based systems.  The ‚ÄúAgentic Community‚Äù initiative will explore the open system design questions presented in the document and construct publicly hosted reference architectures and implementations with accompanying code. Its objective is to provide clarity in system design through published reference materials, thereby offering a broader platform for influencing the industry and ecosystems.  ","version":"Next","tagName":"h2"},{"title":"References and Further Reading‚Äã","type":1,"pageTitle":"Evolving System Architecture: Integrating Agents into Workflow Systems","url":"/docs/Artifacts/evolving-systems-architecture#references-and-further-reading","content":" Agentic AI Identity Management Approach (March 11, 2025) Retrieved May 19, 2025, from https://cloudsecurityalliance.org/blog/2025/03/11/agentic-ai-identity-management-approach  Buddhika ‚ÄúFrom Microservices to AI Agents: A Natural Evolution for Developers‚Äù Medium, December 29, 2024.  Cerny, T., Goulis, G., Abdelfattah, A.S. (2025). Towards Change Impact Analysis in Microservices-based System Evolution. arXiv preprint arXiv:2501.11778.  Deng, Z., Guo, Y., Han, C., Ma, W., Xiong, J., Wen, S., &amp; Xiang, Y. (2025). Ai agents under threat: A survey of key security challenges and future pathways. ACM Computing Surveys, 57(7), 1-36.  Fowler, M., &amp; Lewis, J. (2014). Microservices: a definition of this new architectural term. Retrieved May 9, 2025, from https://martinfowler.com/articles/microservices.html  GRPC (n.d.). Retrieved May 9, 2025, from https://grpc.io/docs/languages/go/basics/  H√§ndler, T. (2023). Balancing Autonomy and Alignment: A Multi-Dimensional Taxonomy for Autonomous LLM-powered Multi-Agent Architectures. arXiv preprint arXiv:2310.03659.  Richardson, C. (2019). Microservices Patterns: With examples in Java. Manning Publications.  Solo.io (April 24, 2025). Retrieved May 18, 2025, from https://www.solo.io/blog/agent-mesh-for-enterprise-agents  Swagger (n.d.). Retrieved May 9, 2025, from https://swagger.io/docs/open-source-tools/swagger-codegen/codegen-v3/about/  Yang, Y., Chai, H., Song, Y., Qi, S., Wen, M., Li, N., Liao, J., Hu, H., Lin, J., Chang, G., Liu, W., Wen, Y., Yu, Y., Zhang, W. (2025). A Survey of AI Agent Protocols. arXiv preprint arXiv:2504.16736. ","version":"Next","tagName":"h2"},{"title":"Security Working Group","type":0,"sectionRef":"#","url":"/docs/Working Groups/security","content":"","keywords":"","version":"Next"},{"title":"Working Group Information‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#working-group-information","content":" Slack: #agentic-community-wg-security  üìÑ Meeting Notes  üìÖ Meeting Invite - Sign up for the Google Group  ","version":"Next","tagName":"h2"},{"title":"Gen AI Agent Identity Security Reference Architecture Framework‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#gen-ai-agent-identity-security-reference-architecture-framework","content":" &quot;Gen AI Agent Identity Security Reference Architecture Framework&quot; Authors: Pralay Desai, Electronic Arts, James Ferguson Agentic Community Contributors Copyright ¬© 2025 Agentic Community Licensed under CC BY-SA 4.0 Individual authors retain attribution rights   Purpose  This framework defines identity-centric controls for Gen AI agents, mapping security requirements to each agent component and to end-to-end flows. It emphasizes Zero Trust, least privilege, short-lived credentials, privacy-by-design, and continuous monitoring to reduce risks like impersonation, data exfiltration, and abuse.  Core Principles  1.** Zero Trust by Default**  Every interaction‚Äîbetween users, systems, and services‚Äîmust be verified. Nothing is trusted automatically, even within the same network. Each step of communication (human ‚Üî app, app ‚Üî backend, agent ‚Üî tools/data) requires authentication and authorization.  2. Least Privilege Access  Users and agents get only the permissions needed for their tasks. Access is denied by default and granted only for specific, approved purposes. This reduces damage if credentials are compromised.  3. Short-Lived Credentials  Use temporary credentials that expire quickly and rotate often. This limits exposure if tokens or keys are leaked. Example: short-lived OAuth or mTLS tokens that auto-renew securely.  4. Strong and Verifiable Identity  Every user, service, and AI agent must have a unique, verifiable identity. Service identities should be cryptographically verifiable using systems like SPIFFE/SPIRE or signed tokens, ensuring authenticity and preventing spoofing.  5. Separation of Duties  Separate who decides access (Policy Decision Point) from who enforces it (Policy Enforcement Point). Keep secrets and runtime environments isolated to avoid privilege overlap or misuse.  6. Comprehensive Auditability  All identity-related actions must be logged securely and made tamper-evident. These logs should provide a clear picture of who did what, when, and why‚Äîenabling accountability and quick detection of anomalies.  7. Privacy and Safety by Design  Protect personal and sensitive data through redaction, minimization, and encryption. Ensure AI prompts and data flows adhere to privacy and ethical guidelines, including guardrails to prevent data leaks or unsafe outputs.  Additional Identity Security Principles  8. Context-Aware Access  Access should adapt to context‚Äîsuch as device posture, user location, time, or behavior. For example, deny access from unknown devices or unusual networks even if credentials are valid.  9. Purpose-Based Data Usage  Data access should always align with the intended, approved purpose. AI agents and users must declare their purpose before accessing data, and policies must enforce that declared purpose.  10. Delegated and Impersonated Access with Consent  When an AI agent acts on behalf of a human, it must first obtain explicit, time-bound consent. All impersonated actions must be visible to the human and fully auditable.  11. Continuous Identity Assurance  Identity verification shouldn‚Äôt stop after login. Systems should revalidate user and agent behavior throughout sessions‚Äîdetecting anomalies like sudden location changes or abnormal activity.  12. Defense in Depth  Layer multiple controls‚Äîauthentication, authorization, encryption, monitoring‚Äîso a single failure doesn‚Äôt lead to compromise. Each layer independently protects against misuse or breach.  13. Resilience and Revocation  Enable quick revocation of credentials, sessions, or impersonation rights if a threat is detected. Ensure systems recover gracefully and securely after compromise.  Architecture Diagram    Request Flow Diagram    ","version":"Next","tagName":"h2"},{"title":"Components & Identity Security Requirements‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#components--identity-security-requirements","content":" ","version":"Next","tagName":"h2"},{"title":"Identity & Access Layer (IdP/SSO)‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#identity--access-layer-idpsso","content":" ‚Ä¢ AuthN: OIDC/OAuth 2.1; MFA/WebAuthn; device posture checks; step-up for risk.  ‚Ä¢ AuthZ: Central RBAC/ABAC with PDP; scoped tokens and policy versioning.  ‚Ä¢ Defaults: Deny unauthenticated; token TTL ‚â§ 15m; refresh rotation; cookie HttpOnly/Secure/SameSite.  ‚Ä¢ Standards: OAuth 2.1, OIDC, FIDO2/WebAuthn, NIST 800-63.  ‚Ä¢ Guardrails: Phishing-resistant login; replay protection (DPoP/PoP); session anomaly detection.  ","version":"Next","tagName":"h2"},{"title":"Frontend (UI/Chat/API Gateway ‚Äì PEP)‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#frontend-uichatapi-gateway--pep","content":" ‚Ä¢ AuthN: Validate OIDC/OAuth 2.1 tokens (iss/aud/exp/nbf); TLS 1.3 everywhere.  ‚Ä¢ AuthZ: Coarse-grained PEP at gateway; route-based scopes; quota &amp; rate limits per subject.  ‚Ä¢ Defaults: Schema validation; deny oversized prompts/uploads; strict CORS/CSRF.  ‚Ä¢ Standards: JWT with RS256/ES256; OWASP ASVS &amp; API Security Top 10.  ‚Ä¢ Guardrails: Input sanitization; prompt pre-filters; DLP on uploads; bot/automation detection.  ","version":"Next","tagName":"h2"},{"title":"Orchestrator / Router‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#orchestrator--router","content":" ‚Ä¢ AuthN: Validates caller tokens; attaches service identity (mTLS/JWT) to downstream calls.  ‚Ä¢ AuthZ: Purpose binding for memory &amp; tools; policy checks with PDP per action.  ‚Ä¢ Defaults: Deny unknown tools/skills; allow-list external endpoints; concurrency caps.  ‚Ä¢ Standards: OAuth 2.1 service flows; Zero Trust (NIST SP 800-207).  ‚Ä¢ Guardrails: Prompt isolation between tenants/sessions; circuit breakers; red-team tested system prompts.  ","version":"Next","tagName":"h2"},{"title":"Agent Runtime ‚Äì Components of Agents‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#agent-runtime--components-of-agents","content":" ‚Ä¢ AuthN: mTLS between components; SPIFFE/SPIRE SVIDs or signed service tokens.  ‚Ä¢ AuthZ: Capability tokens per component (planner, tools, memory, RAG); sandbox untrusted tools.  ‚Ä¢ Defaults: Memory and tool access are deny-by-default; strict IPC schemas.  ‚Ä¢ Standards: OAuth 2.1, SPIFFE/SPIRE, TLS 1.3, secure IPC patterns.  ‚Ä¢ Guardrails: Integrity &amp; replay protection; egress allow-lists; component health &amp; anomaly checks.  ","version":"Next","tagName":"h2"},{"title":"Planner‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#planner","content":" ‚Ä¢ AuthN: Accepts only authenticated orchestration requests (mTLS/service token).  ‚Ä¢ AuthZ: Can request tools/memory only via policy-approved interfaces.  ‚Ä¢ Defaults: No direct data access; read-only planning by default.  ‚Ä¢ Guardrails: Token budget limits; prevent tool invocation loops; log plan diffs.  ","version":"Next","tagName":"h2"},{"title":"Tools Adapter / Skills Broker‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#tools-adapter--skills-broker","content":" ‚Ä¢ AuthN: Per-tool credentials are short-lived &amp; scoped; secure secret retrieval via KMS/HSM.  ‚Ä¢ AuthZ: Tool scopes per tenant/use case; explicit allow-list of functions and destinations.  ‚Ä¢ Defaults: Deny new tools until reviewed; sandbox untrusted tools.  ‚Ä¢ Standards: OAuth 2.1 client credentials / token exchange (RFC 8693); signed webhooks.  ‚Ä¢ Guardrails: Egress proxy with DLP; output validation; rate &amp; concurrency limits.  ","version":"Next","tagName":"h2"},{"title":"Memory Store (Short/Long-Term)‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#memory-store-shortlong-term","content":" ‚Ä¢ AuthN: Service identity (mTLS/SVID); client-bound tokens for sessions.  ‚Ä¢ AuthZ: Row/column/namespace ACL; tenant separation; purpose-limited writes/reads.  ‚Ä¢ Defaults: Encrypt at rest; deny cross-tenant reads; retention limits by policy.  ‚Ä¢ Standards: AES-256 at rest, TLS 1.3 in transit; privacy frameworks (ISO/IEC 27555).  ‚Ä¢ Guardrails: PII redaction; data minimization before write; differential privacy where applicable.  ","version":"Next","tagName":"h2"},{"title":"Retrieval/RAG Index‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#retrievalrag-index","content":" ‚Ä¢ AuthN: Signed requests with scoped tokens; signed URLs for artifacts.  ‚Ä¢ AuthZ: Query-time masking; context window filters by subject &amp; purpose.  ‚Ä¢ Defaults: No default collections; explicit opt-in; max context size caps.  ‚Ä¢ Standards: Attribute-based filters; searchable encryption patterns.  ‚Ä¢ Guardrails: DLP scanning of retrieved chunks; lineage tags and watermarks in responses.  ","version":"Next","tagName":"h2"},{"title":"Reasoner / LLM‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#reasoner--llm","content":" ‚Ä¢ AuthN: Accepts inputs only via authenticated/runtime-authorized channels.  ‚Ä¢ AuthZ: Tool use gated by PEP; safety policies enforced in-context.  ‚Ä¢ Defaults: Safe policy prompts; blocked capabilities by default (e.g., file system/network).  ‚Ä¢ Standards: Content safety policies; model spec guardrails; inference isolation.  ‚Ä¢ Guardrails: Jailbreak/indirect injection detection; toxicity filters; human-in-the-loop for high risk.  ","version":"Next","tagName":"h2"},{"title":"Policy Decision Point (PDP) & Policy Store‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#policy-decision-point-pdp--policy-store","content":" ‚Ä¢ AuthN: mTLS/service identity; request signing.  ‚Ä¢ AuthZ: Central decisioning for RBAC/ABAC/capabilities; versioned policies; approvals.  ‚Ä¢ Defaults: Deny on policy evaluation errors; audit all decisions.  ‚Ä¢ Standards: OPA/Rego (as applicable); XACML/ALFA patterns; NIST 800-207.  ‚Ä¢ Guardrails: Break-glass policies with alerts; regression tests for policy changes.  ","version":"Next","tagName":"h2"},{"title":"Secrets & Key Management (KMS/HSM)‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#secrets--key-management-kmshsm","content":" ‚Ä¢ AuthN: Strong service auth to KMS/HSM; attestation before key use where possible.  ‚Ä¢ AuthZ: Least-privilege key grants; per-tenant key material; envelope encryption.  ‚Ä¢ Defaults: No plaintext secrets in code/prompts/env; rotation &amp; revocation SLAs.  ‚Ä¢ Standards: FIPS 140-2/3 HSM; AES-256; RSA/ECC best practices.  ‚Ä¢ Guardrails: Access anomaly alerts; dual control for key exports; tamper-evident logging.  ","version":"Next","tagName":"h2"},{"title":"Data Access Broker‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#data-access-broker","content":" ‚Ä¢ AuthN: STS/short-lived OAuth tokens; signed URLs; client binding (DPoP/PoP).  ‚Ä¢ AuthZ: Row/column security; query allow-lists; purpose constraints.  ‚Ä¢ Defaults: Deny-by-default; masking/redaction by default for sensitive fields.  ‚Ä¢ Standards: TLS 1.3; privacy regulations (GDPR/CCPA) alignment.  ‚Ä¢ Guardrails: DLP, watermarking; query cost/volume limits; exfil alerts.  ","version":"Next","tagName":"h2"},{"title":"Observability & Audit‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#observability--audit","content":" ‚Ä¢ AuthN: Authenticated log/metrics pipelines; secure agents for telemetry.  ‚Ä¢ AuthZ: Redaction of sensitive data; role-based access for logs.  ‚Ä¢ Defaults: Immutable, time-synced logs; retention by policy; tenant scoping.  ‚Ä¢ Standards: OpenTelemetry; W3C trace context; CIS logging controls.  ‚Ä¢ Guardrails: Anomaly detection for AuthZ abuse; protected storage; incident triage hooks.  Identity-Critical Flows  ","version":"Next","tagName":"h2"},{"title":"‚Ä¢ End-User Login ‚Üí IdP (OIDC/OAuth 2.1 + MFA/WebAuthn) ‚Üí token issued ‚Üí FE stores HttpOnly cookie ‚Üí API GW validates.‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#-end-user-login--idp-oidcoauth-21--mfawebauthn--token-issued--fe-stores-httponly-cookie--api-gw-validates","content":" ‚Ä¢ Request Execution ‚Üí FE‚ÜíGateway (PEP)‚ÜíOrchestrator‚ÜíAgent Components (mTLS/JWT)‚ÜíTools/Data (scoped, short-lived creds).  ‚Ä¢ On-Behalf-Of ‚Üí Step-up MFA/consent ‚Üí delegated token (RFC 8693) ‚Üí auto-expire ‚â§30m ‚Üí full audit trail.  ‚Ä¢ Memory Access ‚Üí PEP‚ÜíPDP purpose check ‚Üí masked read/write ‚Üí DLP post-check and lineage tags.  Extended Security Requirements  ","version":"Next","tagName":"h2"},{"title":"Contextual Resource Access‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#contextual-resource-access","content":" Contextual access control enforces security by validating context signals such as user location, device posture, network zone, and time of access. These signals determine whether access should be granted or restricted. This ensures higher security for sensitive operations by dynamically adjusting controls.  Example: A Gen AI agent denies access to sensitive training data if the request originates from an unmanaged device.  ","version":"Next","tagName":"h2"},{"title":"Attribute-Based Access Control (ABAC)‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#attribute-based-access-control-abac","content":" ABAC policies leverage attributes of users, resources, and the environment to make fine-grained access decisions. Attributes can include role, clearance level, resource classification, or session risk score.  Example: A user with the attribute 'role=data_scientist' and clearance 'PII-read' may access anonymized datasets but not raw PII.  ","version":"Next","tagName":"h2"},{"title":"Purpose-Based Access Control (PBAC)‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#purpose-based-access-control-pbac","content":" Purpose-based access ensures that data or resources are accessed only when the purpose aligns with policy-approved activities. Every request is tagged with a declared purpose, and policies validate alignment before granting access.  Example: An AI agent can access patient data for 'treatment' purposes but is denied when the declared purpose is 'marketing'.  ","version":"Next","tagName":"h2"},{"title":"Resource-Bound Access Tokens (RBT)‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#resource-bound-access-tokens-rbt","content":" Resource-bound access tokens are cryptographically bound to a specific resource or context, preventing token misuse across other systems. They ensure that even if a token is stolen, it cannot be replayed against unauthorized resources.  Example: A short-lived JWT bound to a specific RAG collection cannot be reused to query unrelated datasets.  Appendix A ‚Äì Examples of Advanced Security Controls  ‚Ä¢ Contextual Access: Deny cross-border access attempts to sensitive datasets outside approved geographies.  ‚Ä¢ ABAC: Allow only agents tagged with 'confidential-project=true' to access internal research repositories.  ‚Ä¢ PBAC: Enforce purpose tags in API calls; reject access if the declared purpose does not match approved use cases.  ‚Ä¢ RBT: Issue resource-scoped tokens for each microservice call; reject replayed tokens at unrelated services.  Identity Security for Human Impersonation by Gen AI Agents  Human impersonation by Gen AI agents introduces unique security risks. When agents act on behalf of a human, the system must enforce strict identity assurance, explicit consent, and auditable boundaries. These requirements prevent misuse of impersonation capabilities while preserving legitimate use cases such as delegated task execution.  ","version":"Next","tagName":"h2"},{"title":"Security Principles‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#security-principles","content":" ‚Ä¢ Explicit Consent: Humans must grant informed, time-bound consent before impersonation begins.  ‚Ä¢ Least Privilege: Impersonated sessions inherit only the minimum privileges required for the delegated task.  ‚Ä¢ Transparency: All impersonated actions must be clearly visible to the human and logged for audit.  ‚Ä¢ Revocability: Humans must have the ability to revoke impersonation rights at any time.  ‚Ä¢ Accountability: Immutable logs and alerts ensure traceability of impersonated actions.  ","version":"Next","tagName":"h2"},{"title":"Security Requirements‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#security-requirements","content":" ‚Ä¢ Authentication (AuthN): Require strong step-up authentication (e.g., MFA/WebAuthn) before an agent begins impersonation.  ‚Ä¢ Authorization (AuthZ): Scope impersonation tokens narrowly, limiting them to predefined tasks or resources.  ‚Ä¢ Defaults: Impersonation sessions auto-expire within short time windows (e.g., ‚â§30 minutes).  ‚Ä¢ Guardrails: Notify the human of each impersonated action in real time and maintain detailed audit logs.  ‚Ä¢ Standards: Align impersonation flows with OAuth 2.1 'on-behalf-of' grants (RFC 8693) and NIST 800-63 digital identity assurance levels.  Appendix B ‚Äì Examples of Human Impersonation Controls  ‚Ä¢ An AI assistant impersonates a support agent to reset a customer password, but only after the human approves via MFA.  ‚Ä¢ An agent impersonates a project manager to schedule meetings, but cannot access the manager‚Äôs financial approvals.  ‚Ä¢ Each impersonated action (e.g., sending an email) triggers a notification to the human for transparency.  ‚Ä¢ Impersonation tokens expire after 20 minutes, requiring renewal with explicit human consent.  Practical Example ‚Äì End-to-End Implementation  Login &amp; Context: The support agent signs in via OIDC/OAuth 2.1 with WebAuthn (MFA). Frontend captures context (managed device, corp network) and risk score. Token Validation &amp; PEP: API Gateway validates iss/aud/exp and enforces rate/quota, schema checks, and CSRF/CORS protections. Purpose &amp; Policy: The request is tagged purpose=customer_support_refund. Orchestrator calls PDP, which evaluates ABAC (role=csr, region allowed), PBAC (purpose matches policy), and contextual rules (device posture). Scoped Credentials: Tools Adapter requests a short-lived Resource-Bound Token (RBT) from KMS/Data Broker scoped to orders:read and orders:refund for collection=orders_eu only. Retrieval with Minimization: RAG fetch narrows to necessary fields (order_id, status, amount) with row/column ACL; guardrails scan retrieved chunks (DLP). Human Impersonation: For email send as the human agent, system prompts step-up MFA and explicit consent; issues on-behalf-of token limited to send_email:refund_ack for 20 minutes. Execution &amp; Guardrails: Reasoner prepares refund; Guardrails check for policy/prompt violations; Orchestrator executes tool call using RBT; email sent with impersonation token. Audit &amp; Alerts: Observability records who/what/when/why (purpose, scopes, token IDs). Anomaly detection monitors unusual access or refund volumes.  ","version":"Next","tagName":"h2"},{"title":"Requirement Mapping‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#requirement-mapping","content":" ‚Ä¢ Contextual Resource Access ‚Üí Steps 1 &amp; 3 (device posture, network zone, risk).  ‚Ä¢ ABAC ‚Üí Step 3 (role=csr, region=EU applied at PDP).  ‚Ä¢ Purpose-Based Access Control ‚Üí Steps 3 &amp; 8 (purpose=customer_support_refund).  ‚Ä¢ Resource-Bound Access Tokens ‚Üí Step 4 (RBT scoped to orders_eu with orders:refund).  ‚Ä¢ Human Impersonation Controls ‚Üí Step 6 (MFA, consent, OBO token with 20m TTL).  ","version":"Next","tagName":"h2"},{"title":"Practical Example Diagram‚Äã","type":1,"pageTitle":"Security Working Group","url":"/docs/Working Groups/security#practical-example-diagram","content":"   Summary Table ‚Äì Security Requirements per Component  The table below provides a condensed view of key security requirements for each Gen AI agent component. It highlights Authentication (AuthN), Authorization (AuthZ), and advanced access models (ABAC, PBAC, RBT, Contextual Access).  Component\tAuthN\tAuthZ / Access Control\tAdvanced ControlsIdP / SSO\tOIDC/OAuth 2.1, MFA/WebAuthn, Device binding\tCentral RBAC with PDP\tContextual access, step-up auth Frontend (PEP)\tValidate JWT, TLS 1.3, CSRF protection\tPEP with scopes, deny-by-default\tABAC, PBAC, schema validation, DLP Orchestrator\tService JWT/mTLS\tPDP evaluation\tPurpose binding, ABAC+PBAC Agent Runtime\tSPIFFE/SPIRE SVIDs, mTLS\tCapability tokens per component\tSandbox isolation, integrity checks Planner\tAuthenticated requests\tPolicy-limited tool/memory requests\tLoop/budget limits Tools Adapter\tShort-lived creds from KMS\tScoped tool access per tenant\tRBT, DLP, rate limiting Memory Store\tMTLS, PoP tokens\tNamespace/row/col ACL, PBAC\tEncryption, minimization, anomaly alerts Retrieval / RAG\tSigned scoped tokens, RBT\tQuery masking, ABAC filters\tPBAC enforcement, DLP scans Reasoner / LLM\tRuntime-only authenticated access\tPEP-gated tool use\tPolicy prompts, jailbreak/PII filters PDP\tmTLS, request signing\tCentral RBAC/ABAC/Capabilities\tPBAC, contextual checks KMS / HSM\tService auth, attestation\tLeast privilege grants\tRotation, dual control, anomaly alerts Data Access Broker\tSTS tokens, RBT\tRow/column security, PBAC\tMasking, DLP, watermarking Observability &amp; Audit\tAuthenticated telemetry\tRBAC on logs\tImmutable logs, anomaly detection Egress Proxy / Guardrails\tn/a\tAllow-lists enforced\tDLP, classifiers, watermarking Federation\tOIDC/SAML signed assertions\tAttribute‚ÜíRBAC mapping\tContextual isolation, drift detection Human Impersonation\tStep-up MFA/WebAuthn\tScoped OBO token\tConsent, PBAC, auditability External SaaS\tOAuth 2.1 client creds\tPer-SaaS scopes\tRBT per SaaS, DLP, egress proxy MCP Host/Servers\tMTLS/service tokens\tRegistry of allowed tools/resources\tRBT per server, sandboxing ","version":"Next","tagName":"h2"}],"options":{"id":"default"}}